DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:14)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x15ff3565 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x15ff35650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0004, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x15ff35650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x15ff3565-0x154ffacdbcb0004 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967393,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967393,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7bdadd59
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7e6178ce, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967393,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967393,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x15ff3565-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x15ff3565-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0004
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0004
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0004
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967394,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0004
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0004 : Unable to read additional data from server sessionid 0x154ffacdbcb0004, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0004 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:11)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x25930632 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x259306320x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0002, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x259306320x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x25930632-0x254ffacd97d0002 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967395,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967395,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2d4f3d22
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@50893e4c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967395,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967395,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967395,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967395,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1015cde3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1015cde30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0004, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1015cde30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1015cde3-0x54ffacd8fd0004 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967407,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967407,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@29de3685, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967407,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967407,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1015cde3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1015cde3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x1015cde3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1015cde3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0004
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0004
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0004
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967408,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0004
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0004 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x11ff4a1c connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x11ff4a1c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0003, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x11ff4a1c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x11ff4a1c-0x254ffacd97d0003 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967409,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967409,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6139406a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967409,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967409,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x11ff4a1c-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x11ff4a1c-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0003
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0003
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0003
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967410,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0003
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0003 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:14)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x511c413d connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x511c413d0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0004, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x511c413d0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x511c413d-0x254ffacd97d0004 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967411,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967411,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2a24865f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4f5c1769, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967411,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967411,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x511c413d-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x511c413d-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0004
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0004
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0004
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967412,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0004
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0004 : Unable to read additional data from server sessionid 0x254ffacd97d0004, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0004 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:14)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x3f357ede connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x3f357ede0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0005, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3f357ede0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3f357ede-0x154ffacdbcb0005 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967413,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967413,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2a24865f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4f5c1769, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967413,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967413,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x3f357ede-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x3f357ede-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0005
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0005
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0005
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967414,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0005
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0005 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0005 : Unable to read additional data from server sessionid 0x154ffacdbcb0005, likely server has closed socket
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:19)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x21dec6bf connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x21dec6bf0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0005, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x21dec6bf0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x21dec6bf-0x54ffacd8fd0005 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967416,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967416,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6d14693f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7393358c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967416,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967416,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967416,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967416,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x540733b1 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x540733b10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0006, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x540733b10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x540733b1-0x54ffacd8fd0006 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967440,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967440,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15e7ae59, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967440,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967440,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x540733b1-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x540733b1-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x540733b1-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x540733b1-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0006
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0006
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0006
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967441,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0006
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0006 : Unable to read additional data from server sessionid 0x54ffacd8fd0006, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0006 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x313314a connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x313314a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0005, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x313314a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x313314a-0x254ffacd97d0005 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967442,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967442,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7b67390d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967442,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967442,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x313314a-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x313314a-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0005
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0005
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0005
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967443,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0005 : Unable to read additional data from server sessionid 0x254ffacd97d0005, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0005
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0005 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x595938f3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x595938f30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0006, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x595938f30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x595938f3-0x154ffacdbcb0006 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967444,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967444,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5893efc3
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6be79d4a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967444,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967444,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x595938f3-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x595938f3-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0006
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0006
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0006
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967445,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0006
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0006 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x59db869 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x59db8690x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0006, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x59db8690x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x59db869-0x254ffacd97d0006 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967447,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967447,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6ec710ba
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@102049d5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967447,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967447,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967447,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967447,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x238f4a11 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x238f4a110x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0007, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x238f4a110x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x238f4a11-0x54ffacd8fd0007 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967471,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967471,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6a6252c1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967471,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967471,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x238f4a11-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x238f4a11-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x238f4a11-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x238f4a11-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0007
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0007
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0007
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967472,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0007
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0007 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6709fce5 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6709fce50x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0007, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6709fce50x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6709fce5-0x154ffacdbcb0007 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967473,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967473,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@e68b3db, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967473,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967473,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6709fce5-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6709fce5-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0007
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0007
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0007
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967474,0  request:: null response:: null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0007 : Unable to read additional data from server sessionid 0x154ffacdbcb0007, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0007
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0007 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7fcfe433 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x7fcfe4330x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0008, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7fcfe4330x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7fcfe433-0x154ffacdbcb0008 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967475,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967475,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@14dda791
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@739e3169, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967475,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967475,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967475,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967475,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2c1309bd connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2c1309bd0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0007, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2c1309bd0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2c1309bd-0x254ffacd97d0007 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967500,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967500,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@61616da4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967500,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967500,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x2c1309bd-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x2c1309bd-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0007
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0007
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0007
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967501,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0007
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0007 : Unable to read additional data from server sessionid 0x254ffacd97d0007, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0007 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1b209640 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1b2096400x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0008, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1b2096400x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1b209640-0x254ffacd97d0008 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967502,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967502,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@464a8194, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967502,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967502,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1b209640-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1b209640-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0008
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0008
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0008
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967503,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0008
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0008 : Unable to read additional data from server sessionid 0x254ffacd97d0008, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0008 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x577bcfe3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x577bcfe30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0009, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x577bcfe30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x577bcfe3-0x254ffacd97d0009 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967505,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967505,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2d369a6b
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@657120fa
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4770cfdf, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967505,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967505,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967505,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967505,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x264948a0 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x264948a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0009, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x264948a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x264948a0-0x154ffacdbcb0009 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967529,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967529,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@64bd8f9c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967529,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967529,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x264948a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x264948a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x264948a0-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x264948a0-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0009
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0009
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0009
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967530,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0009
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0009 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0009 : Unable to read additional data from server sessionid 0x154ffacdbcb0009, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x464a8194 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x464a81940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x464a81940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x464a8194-0x154ffacdbcb000a connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967531,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967531,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7a85b031, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967531,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967531,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x464a8194-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x464a8194-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000a
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967532,0  request:: null response:: null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000a : Unable to read additional data from server sessionid 0x154ffacdbcb000a, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000a closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@657120fa
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@657120fa
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@657120fa
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5c9a87f2 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5c9a87f20x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0008, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5c9a87f20x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5c9a87f2-0x54ffacd8fd0008 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967534,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967534,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@42c10b8a
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@48c56835, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967534,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967534,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967534,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967534,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x119fc7a0 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x119fc7a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0009, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x119fc7a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x119fc7a0-0x54ffacd8fd0009 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967558,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967558,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@23e7cde4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967558,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967558,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x119fc7a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x119fc7a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0009
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0009
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0009
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967559,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0009
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0009 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0009 : Unable to read additional data from server sessionid 0x54ffacd8fd0009, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x8092265 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x80922650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x80922650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x8092265-0x54ffacd8fd000a connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967560,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967560,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7e9b4e48, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967560,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967560,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x8092265-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x8092265-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000a
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967561,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000a
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000a : Unable to read additional data from server sessionid 0x54ffacd8fd000a, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000a closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x3dec0a94 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x3dec0a940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3dec0a940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3dec0a94-0x254ffacd97d000a connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967562,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967562,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6341683a
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@da565c6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967562,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967562,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967562,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967562,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x227ed534 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x227ed5340x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x227ed5340x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x227ed534-0x154ffacdbcb000b connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967586,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967586,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3d090e84, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967586,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967586,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x227ed534-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x227ed534-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000b
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000b
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967587,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000b
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000b : Unable to read additional data from server sessionid 0x154ffacdbcb000b, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000b closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x9e00bf3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x9e00bf30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x9e00bf30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x9e00bf3-0x254ffacd97d000b connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967588,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967588,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3833089c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967588,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967588,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x9e00bf3-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x9e00bf3-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d000b
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d000b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d000b
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967589,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d000b : Unable to read additional data from server sessionid 0x254ffacd97d000b, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d000b
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d000b closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6cd827df connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6cd827df0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6cd827df0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6cd827df-0x54ffacd8fd000b connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967590,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967590,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5f828696
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3563739, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967590,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967590,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967590,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967590,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2062f62f connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2062f62f0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2062f62f0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2062f62f-0x154ffacdbcb000c connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967614,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967614,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@76fe48e4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967615,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967615,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x2062f62f-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x2062f62f-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000c
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967616,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000c : Unable to read additional data from server sessionid 0x154ffacdbcb000c, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xad9be15 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0xad9be150x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xad9be150x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xad9be15-0x254ffacd97d000c connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967617,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967617,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@54308395, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967617,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967617,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0xad9be15-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0xad9be15-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d000c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d000c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d000c
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967618,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d000c
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d000c : Unable to read additional data from server sessionid 0x254ffacd97d000c, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d000c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x298f11d3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x298f11d30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x298f11d30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x298f11d3-0x254ffacd97d000d connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967620,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967620,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2963aa3
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@53b5fb5b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967620,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967620,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967620,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967620,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x153f1403 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x153f14030x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x153f14030x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x153f1403-0x154ffacdbcb000d connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967644,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967644,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2b10ef0a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967644,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967644,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x153f1403-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x153f1403-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x153f1403-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x153f1403-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000d
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967645,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000d
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000d : Unable to read additional data from server sessionid 0x154ffacdbcb000d, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000d closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x28767975 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x287679750x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x287679750x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967646,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x28767975-0x254ffacd97d000e connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967646,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@ad9be15, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967646,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967646,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x28767975-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x28767975-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d000e
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d000e
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d000e
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967647,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d000e
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d000e : Unable to read additional data from server sessionid 0x254ffacd97d000e, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d000e closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x18d6cf4 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x18d6cf40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x18d6cf40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x18d6cf4-0x254ffacd97d000f connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967650,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967650,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@3ac81c24
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@e1be26c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967650,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967650,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967650,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967650,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x603adbda connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x603adbda0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x603adbda0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967674,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x603adbda-0x54ffacd8fd000c connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967674,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@64bd8f9c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967674,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967674,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x603adbda-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x603adbda-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x603adbda-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x603adbda-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000c
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967675,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000c : Unable to read additional data from server sessionid 0x54ffacd8fd000c, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7a200513 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x7a2005130x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7a2005130x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7a200513-0x54ffacd8fd000d connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967676,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967676,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5d4e5a43, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967676,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967676,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x7a200513-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x7a200513-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000d
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967677,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000d
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000d : Unable to read additional data from server sessionid 0x54ffacd8fd000d, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000d closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x43413f6c connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x43413f6c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x43413f6c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x43413f6c-0x154ffacdbcb000e connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967679,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967679,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6a52da3c
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@114380e5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967679,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967679,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967679,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967679,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x41109845 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x41109845-0x54ffacd8fd000e connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967703,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967703,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3063adc4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967703,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967703,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000e
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000e
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000e
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967704,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000e
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000e closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000e : Unable to read additional data from server sessionid 0x54ffacd8fd000e, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x24a7d709 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x24a7d7090x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x24a7d7090x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x24a7d709-0x154ffacdbcb000f connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967705,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967705,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@24d95700, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967705,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967705,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x24a7d709-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x24a7d709-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000f
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000f
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000f
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967706,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000f
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000f closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6321d94c connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6321d94c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6321d94c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6321d94c-0x54ffacd8fd000f connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967708,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967708,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@725212d6
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@66c3433d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967708,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967708,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967708,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967708,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x41109845 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0010, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967732,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x41109845-0x54ffacd8fd0010 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967732,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3063adc4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967732,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967732,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0010
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0010
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0010
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967733,0  request:: null response:: null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0010 : Unable to read additional data from server sessionid 0x54ffacd8fd0010, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0010
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0010 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x716a2ac connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x716a2ac0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0010, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x716a2ac0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x716a2ac-0x254ffacd97d0010 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967734,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967734,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@38ded3e6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967734,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967734,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x716a2ac-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x716a2ac-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0010
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0010
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0010
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967735,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0010
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0010 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0010 : Unable to read additional data from server sessionid 0x254ffacd97d0010, likely server has closed socket
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 