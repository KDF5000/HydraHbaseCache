DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:14)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x15ff3565 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x15ff35650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0004, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x15ff35650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x15ff3565-0x154ffacdbcb0004 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967393,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967393,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7bdadd59
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7e6178ce, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967393,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967393,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x15ff3565-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x15ff3565-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0004
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0004
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0004
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0004, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967394,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0004
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0004 : Unable to read additional data from server sessionid 0x154ffacdbcb0004, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0004 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@73b4f342
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:11)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x25930632 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x259306320x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0002, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x259306320x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x25930632-0x254ffacd97d0002 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967395,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967395,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2d4f3d22
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@50893e4c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967395,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967395,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967395,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0002, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967395,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1015cde3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1015cde30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0004, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1015cde30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1015cde3-0x54ffacd8fd0004 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967407,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967407,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@29de3685, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967407,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967407,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1015cde3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1015cde3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x1015cde3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1015cde3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0004
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0004
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0004
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0004, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967408,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0004
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0004 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x11ff4a1c connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x11ff4a1c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0003, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x11ff4a1c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x11ff4a1c-0x254ffacd97d0003 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967409,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967409,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6139406a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967409,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967409,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x11ff4a1c-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x11ff4a1c-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0003
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0003
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0003
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0003, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967410,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0003
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0003 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7a95626d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:14)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x511c413d connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x511c413d0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0004, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x511c413d0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x511c413d-0x254ffacd97d0004 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967411,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967411,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2a24865f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4f5c1769, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967411,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967411,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x511c413d-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x511c413d-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0004
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0004
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0004
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0004, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967412,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0004
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0004 : Unable to read additional data from server sessionid 0x254ffacd97d0004, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0004 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testPut(HydraCacheClientImplTest.java:14)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x3f357ede connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x3f357ede0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0005, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3f357ede0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3f357ede-0x154ffacdbcb0005 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967413,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967413,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2a24865f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4f5c1769, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967413,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967413,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x3f357ede-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x3f357ede-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0005
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0005
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0005
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0005, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967414,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0005
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0005 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0005 : Unable to read additional data from server sessionid 0x154ffacdbcb0005, likely server has closed socket
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1533a69e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:19)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x21dec6bf connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x21dec6bf0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0005, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x21dec6bf0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x21dec6bf-0x54ffacd8fd0005 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967416,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967416,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6d14693f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7393358c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967416,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967416,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967416,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0005, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967416,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x540733b1 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x540733b10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0006, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x540733b10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x540733b1-0x54ffacd8fd0006 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967440,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967440,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@15e7ae59, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967440,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967440,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x540733b1-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x540733b1-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x540733b1-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x540733b1-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0006
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0006
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0006
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0006, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967441,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0006
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0006 : Unable to read additional data from server sessionid 0x54ffacd8fd0006, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0006 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x313314a connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x313314a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0005, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x313314a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x313314a-0x254ffacd97d0005 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967442,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967442,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7b67390d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967442,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967442,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x313314a-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x313314a-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0005
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0005
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0005
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0005, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967443,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0005 : Unable to read additional data from server sessionid 0x254ffacd97d0005, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0005
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0005 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:236)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x595938f3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x595938f30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0006, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x595938f30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x595938f3-0x154ffacdbcb0006 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967444,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967444,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5893efc3
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6be79d4a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967444,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967444,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x595938f3-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x595938f3-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0006
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0006
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0006
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0006, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967445,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0006
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0006 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@6b27e9e9
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x59db869 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x59db8690x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0006, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x59db8690x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x59db869-0x254ffacd97d0006 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967447,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967447,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6ec710ba
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@102049d5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967447,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967447,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967447,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0006, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967447,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x238f4a11 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x238f4a110x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0007, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x238f4a110x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x238f4a11-0x54ffacd8fd0007 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967471,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967471,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6a6252c1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967471,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967471,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x238f4a11-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x238f4a11-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x238f4a11-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x238f4a11-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0007
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0007
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0007
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0007, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967472,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0007
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0007 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6709fce5 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6709fce50x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0007, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6709fce50x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6709fce5-0x154ffacdbcb0007 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967473,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967473,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@e68b3db, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967473,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967473,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6709fce5-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6709fce5-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0007
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0007
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0007
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0007, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967474,0  request:: null response:: null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0007 : Unable to read additional data from server sessionid 0x154ffacdbcb0007, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0007
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0007 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@79c86bc6
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7fcfe433 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x7fcfe4330x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0008, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7fcfe4330x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7fcfe433-0x154ffacdbcb0008 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967475,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967475,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@14dda791
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@739e3169, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967475,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967475,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967475,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0008, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967475,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2c1309bd connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2c1309bd0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0007, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2c1309bd0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2c1309bd-0x254ffacd97d0007 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967500,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967500,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@61616da4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967500,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967500,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x2c1309bd-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x2c1309bd-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0007
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0007
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0007
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0007, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967501,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0007
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0007 : Unable to read additional data from server sessionid 0x254ffacd97d0007, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0007 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1b209640 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1b2096400x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0008, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1b2096400x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1b209640-0x254ffacd97d0008 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967502,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967502,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@464a8194, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967502,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967502,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1b209640-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1b209640-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0008
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0008
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0008
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0008, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967503,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0008
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0008 : Unable to read additional data from server sessionid 0x254ffacd97d0008, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0008 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@3ac04f43
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x577bcfe3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x577bcfe30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0009, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x577bcfe30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x577bcfe3-0x254ffacd97d0009 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967505,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967505,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2d369a6b
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@657120fa
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4770cfdf, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967505,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967505,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967505,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0009, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967505,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x264948a0 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x264948a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0009, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x264948a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x264948a0-0x154ffacdbcb0009 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967529,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967529,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@64bd8f9c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967529,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967529,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x264948a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x264948a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x264948a0-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x264948a0-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0009
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0009
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0009
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0009, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967530,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0009
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0009 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0009 : Unable to read additional data from server sessionid 0x154ffacdbcb0009, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x464a8194 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x464a81940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x464a81940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x464a8194-0x154ffacdbcb000a connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967531,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967531,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7a85b031, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967531,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967531,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x464a8194-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x464a8194-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000a
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967532,0  request:: null response:: null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000a : Unable to read additional data from server sessionid 0x154ffacdbcb000a, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000a closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@657120fa
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@657120fa
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@657120fa
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5c9a87f2 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5c9a87f20x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0008, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5c9a87f20x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5c9a87f2-0x54ffacd8fd0008 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967534,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967534,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@42c10b8a
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@48c56835, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967534,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967534,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967534,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0008, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967534,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x119fc7a0 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x119fc7a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0009, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x119fc7a00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x119fc7a0-0x54ffacd8fd0009 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967558,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967558,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@23e7cde4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967558,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967558,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x119fc7a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x119fc7a0-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0009
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0009
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0009
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0009, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967559,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0009
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0009 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0009 : Unable to read additional data from server sessionid 0x54ffacd8fd0009, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x8092265 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x80922650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x80922650x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x8092265-0x54ffacd8fd000a connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967560,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967560,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7e9b4e48, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967560,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967560,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x8092265-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x8092265-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000a
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967561,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000a
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000a : Unable to read additional data from server sessionid 0x54ffacd8fd000a, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000a closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4b967d0e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x3dec0a94 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x3dec0a940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3dec0a940x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3dec0a94-0x254ffacd97d000a connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967562,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967562,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6341683a
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@da565c6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967562,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967562,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967562,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000a, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967562,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x227ed534 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x227ed5340x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x227ed5340x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x227ed534-0x154ffacdbcb000b connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967586,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967586,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3d090e84, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967586,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967586,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x227ed534-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x227ed534-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000b
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000b
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967587,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000b
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000b : Unable to read additional data from server sessionid 0x154ffacdbcb000b, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000b closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x9e00bf3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x9e00bf30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x9e00bf30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x9e00bf3-0x254ffacd97d000b connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967588,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967588,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3833089c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967588,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967588,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x9e00bf3-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x9e00bf3-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d000b
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d000b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d000b
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967589,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d000b : Unable to read additional data from server sessionid 0x254ffacd97d000b, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d000b
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d000b closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@7b300cde
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6cd827df connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6cd827df0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6cd827df0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6cd827df-0x54ffacd8fd000b connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967590,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967590,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5f828696
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3563739, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967590,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967590,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967590,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000b, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967590,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2062f62f connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2062f62f0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2062f62f0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2062f62f-0x154ffacdbcb000c connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967614,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967614,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@76fe48e4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967615,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967615,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x2062f62f-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x2062f62f-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000c
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967616,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000c : Unable to read additional data from server sessionid 0x154ffacdbcb000c, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xad9be15 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0xad9be150x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xad9be150x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xad9be15-0x254ffacd97d000c connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967617,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967617,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@54308395, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967617,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967617,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0xad9be15-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0xad9be15-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d000c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d000c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d000c
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967618,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d000c
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d000c : Unable to read additional data from server sessionid 0x254ffacd97d000c, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d000c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@6cc294e3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x298f11d3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x298f11d30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x298f11d30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x298f11d3-0x254ffacd97d000d connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967620,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967620,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2963aa3
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@53b5fb5b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967620,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967620,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967620,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000d, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967620,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x153f1403 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x153f14030x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x153f14030x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x153f1403-0x154ffacdbcb000d connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967644,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967644,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2b10ef0a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967644,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967644,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x153f1403-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x153f1403-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x153f1403-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x153f1403-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000d
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967645,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000d
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb000d : Unable to read additional data from server sessionid 0x154ffacdbcb000d, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000d closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x28767975 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x287679750x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x287679750x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967646,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x28767975-0x254ffacd97d000e connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967646,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@ad9be15, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967646,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967646,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x28767975-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x28767975-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d000e
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d000e
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d000e
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967647,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d000e
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d000e : Unable to read additional data from server sessionid 0x254ffacd97d000e, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d000e closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5abc2a8d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x18d6cf4 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x18d6cf40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d000f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x18d6cf40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x18d6cf4-0x254ffacd97d000f connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967650,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967650,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@3ac81c24
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@e1be26c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967650,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967650,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967650,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d000f, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967650,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x603adbda connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x603adbda0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x603adbda0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967674,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x603adbda-0x54ffacd8fd000c connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967674,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@64bd8f9c, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967674,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967674,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x603adbda-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x603adbda-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x603adbda-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x603adbda-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000c
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967675,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000c : Unable to read additional data from server sessionid 0x54ffacd8fd000c, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7a200513 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x7a2005130x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7a2005130x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7a200513-0x54ffacd8fd000d connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967676,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967676,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5d4e5a43, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967676,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967676,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x7a200513-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x7a200513-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000d
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967677,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000d
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000d : Unable to read additional data from server sessionid 0x54ffacd8fd000d, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000d closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x43413f6c connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x43413f6c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x43413f6c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x43413f6c-0x154ffacdbcb000e connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967679,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967679,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6a52da3c
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@114380e5, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967679,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967679,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967679,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000e, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967679,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x41109845 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x41109845-0x54ffacd8fd000e connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967703,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967703,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3063adc4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967703,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967703,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd000e
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd000e
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd000e
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967704,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd000e
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd000e closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd000e : Unable to read additional data from server sessionid 0x54ffacd8fd000e, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x24a7d709 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x24a7d7090x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb000f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x24a7d7090x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x24a7d709-0x154ffacdbcb000f connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967705,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967705,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@24d95700, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967705,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967705,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x24a7d709-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x24a7d709-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb000f
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb000f
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb000f
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb000f, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967706,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb000f
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb000f closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@2cf9f1b5
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:101)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testLocalCache(HydraCacheClientImplTest.java:33)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6321d94c connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6321d94c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd000f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6321d94c0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6321d94c-0x54ffacd8fd000f connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967708,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967708,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@725212d6
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@66c3433d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967708,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967708,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967708,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd000f, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967708,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x41109845 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0010, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x411098450x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967732,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x41109845-0x54ffacd8fd0010 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967732,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3063adc4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967732,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967732,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x41109845-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0010
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0010
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0010
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0010, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967733,0  request:: null response:: null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0010 : Unable to read additional data from server sessionid 0x54ffacd8fd0010, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0010
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0010 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x716a2ac connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x716a2ac0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0010, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x716a2ac0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x716a2ac-0x254ffacd97d0010 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967734,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967734,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@38ded3e6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967734,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967734,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x716a2ac-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x716a2ac-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0010
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0010
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0010
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0010, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967735,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0010
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0010 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0010 : Unable to read additional data from server sessionid 0x254ffacd97d0010, likely server has closed socket
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5abcfadd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:21)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2f7f7b33 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2f7f7b330x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0011, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2f7f7b330x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2f7f7b33-0x254ffacd97d0011 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0011, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967737,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0011, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967737,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6d14693f
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@45a0b59b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0011, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967737,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0011, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967737,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0011, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967737,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0011, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967737,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x37264b74 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x37264b740x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0010, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x37264b740x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x37264b74-0x154ffacdbcb0010 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0010, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967761,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0010, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967761,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@40a81216, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0010, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967761,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0010, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967761,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x37264b74-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x37264b74-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x37264b74-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x37264b74-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0010
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0010
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0010
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0010, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967762,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0010
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0010 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0010 : Unable to read additional data from server sessionid 0x154ffacdbcb0010, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7bf7f640 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x7bf7f6400x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0011, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7bf7f6400x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7bf7f640-0x154ffacdbcb0011 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0011, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967763,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0011, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967763,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@b1152b7, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0011, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967763,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0011, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967763,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x7bf7f640-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x7bf7f640-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0011
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0011
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0011
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0011, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967764,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0011
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0011 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@66f746cc
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:21)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5a7169a1 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5a7169a10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0011, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5a7169a10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5a7169a1-0x54ffacd8fd0011 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0011, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967766,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0011, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967766,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5b785fd1
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@54cd4897
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7e2ab45d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0011, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967766,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0011, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967766,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0011, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967766,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0011, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967766,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xd814cd3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0xd814cd30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0012, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xd814cd30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xd814cd3-0x254ffacd97d0012 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0012, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967790,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0012, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967790,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6de2eb01, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0012, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967790,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0012, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967790,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0xd814cd3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0xd814cd3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0xd814cd3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0xd814cd3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0012
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0012
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0012
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0012, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967791,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0012
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0012 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0012 : Unable to read additional data from server sessionid 0x254ffacd97d0012, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x313314a connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x313314a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0013, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x313314a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x313314a-0x254ffacd97d0013 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0013, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967792,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0013, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967792,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7b67390d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0013, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967792,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0013, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967792,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x313314a-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x313314a-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0013
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0013
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0013
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0013, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967793,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0013
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0013 : Unable to read additional data from server sessionid 0x254ffacd97d0013, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0013 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@54cd4897
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@54cd4897
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@54cd4897
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:238)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[GetGroups], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x416486a6 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x416486a60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0014, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x416486a60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x416486a6-0x254ffacd97d0014 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0014, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967795,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0014, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967795,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@65bb9d54
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5d029929, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0014, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967795,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0014, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967795,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x416486a6-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x416486a6-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0014
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0014
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0014
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0014, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967796,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0014
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0014 closed
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0014 : Unable to read additional data from server sessionid 0x254ffacd97d0014, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:239)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x416486a6 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x416486a60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0012, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x416486a60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x416486a6-0x54ffacd8fd0012 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0012, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967797,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0012, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967797,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@65bb9d54
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@55958273, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0012, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967797,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0012, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967797,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x416486a6-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x416486a6-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0012
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0012
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0012
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0012, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967798,0  request:: null response:: null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0012 : Unable to read additional data from server sessionid 0x54ffacd8fd0012, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0012
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0012 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@1438f98e
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:239)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[GetGroups], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2ec41dd4 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2ec41dd40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0013, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2ec41dd40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2ec41dd4-0x54ffacd8fd0013 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0013, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967799,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0013, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967799,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6f34a809
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@23b804dd
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2040c8a4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0013, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967799,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0013, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967799,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x2ec41dd4-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x2ec41dd4-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0013
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0013
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0013
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0013, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967800,0  request:: null response:: null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0013 : Unable to read additional data from server sessionid 0x54ffacd8fd0013, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0013
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0013 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@23b804dd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@23b804dd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@23b804dd
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:254)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x55de5626 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x55de56260x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0014, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x55de56260x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x55de5626-0x54ffacd8fd0014 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0014, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967801,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0014, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967801,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@6a041fe8
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@6475b7d
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7d349786, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0014, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967801,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0014, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967801,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x55de5626-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x55de5626-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0014
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0014
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0014
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0014, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967802,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0014
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0014 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0014 : Unable to read additional data from server sessionid 0x54ffacd8fd0014, likely server has closed socket
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@6475b7d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@6475b7d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@6475b7d
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:254)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:25)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of successful kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[Rate of failed kerberos logins and latency (milliseconds)], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, about=, value=[GetGroups], type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x416486a6 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x416486a60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0015, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x416486a60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x416486a6-0x254ffacd97d0015 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0015, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967803,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0015, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967803,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@5629fa
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@2887e401
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4aa777ea, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0015, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967803,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0015, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967803,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x416486a6-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x416486a6-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0015
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0015
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0015
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0015, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967804,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0015 : Unable to read additional data from server sessionid 0x254ffacd97d0015, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0015
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0015 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@2887e401
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@2887e401
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@2887e401
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:214)
	at org.apache.hadoop.hbase.client.ConnectionFactory.createConnection(ConnectionFactory.java:119)
	at com.hydra.hydracache.client.HydraCacheClientImpl.get(HydraCacheClientImpl.java:254)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:35)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xf680ba0 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0xf680ba00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0016, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xf680ba00x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xf680ba0-0x254ffacd97d0016 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0016, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967805,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0016, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967805,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@3cca6a55
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@6ce82965
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6aacb24d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0016, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967805,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0016, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967805,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0xf680ba0-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0xf680ba0-metaLookup-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0016
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0016
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0016
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0016, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967806,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0016 : Unable to read additional data from server sessionid 0x254ffacd97d0016, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0016
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0016 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5c7a92e6 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5c7a92e60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0012, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5c7a92e60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5c7a92e6-0x154ffacdbcb0012 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0012, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967807,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0012, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967807,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7c8c0c57, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0012, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967807,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0012, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967807,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0012, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967807,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0012, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967807,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6064bec7 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6064bec70x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0015, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6064bec70x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6064bec7-0x54ffacd8fd0015 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0015, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967831,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0015, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967831,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@23ddab8a, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0015, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967831,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0015, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967831,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6064bec7-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6064bec7-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x6064bec7-shared--pool4-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6064bec7-shared--pool4-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0015
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0015
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0015
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0015, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967832,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0015
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0015 : Unable to read additional data from server sessionid 0x54ffacd8fd0015, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0015 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5ad59375 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5ad593750x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0017, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ad593750x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ad59375-0x254ffacd97d0017 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0017, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967833,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0017, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967833,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7fbb24b1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0017, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967833,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0017, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967833,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x5ad59375-metaLookup-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x5ad59375-metaLookup-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0017
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0017
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0017
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0017, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967834,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0017
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0017 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@6ce82965
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@6ce82965
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@6ce82965
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testRedis(HydraCacheClientImplTest.java:32)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x15563bcf connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x15563bcf0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0018, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x15563bcf0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x15563bcf-0x254ffacd97d0018 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0018, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967835,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0018, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967835,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@28673682
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@17c4fd3
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7f0828b7, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0018, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967835,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0018, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967835,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0018, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967835,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0018, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967835,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6d27bd4b connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6d27bd4b0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0016, negotiated timeout = 90000
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0016, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967859,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0016, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967859,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3467837, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6d27bd4b0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6d27bd4b-0x54ffacd8fd0016 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0016, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967859,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0016, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967859,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6d27bd4b-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6d27bd4b-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0016
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0016
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0016
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0016, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967860,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0016
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0016 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0016 : Unable to read additional data from server sessionid 0x54ffacd8fd0016, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6a8d4e97 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6a8d4e970x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0017, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6a8d4e970x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0017, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967861,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6a8d4e97-0x54ffacd8fd0017 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0017, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967861,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@701faaed, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0017, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967861,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0017, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967861,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6a8d4e97-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6a8d4e97-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0017
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0017
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0017
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0017, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967862,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0017
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0017 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x382bd791 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x382bd7910x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0013, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x382bd7910x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x382bd791-0x154ffacdbcb0013 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0013, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967886,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0013, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967886,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3ad836c1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0013, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967886,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0013, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967886,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x382bd791-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x382bd791-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x382bd791-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x382bd791-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0013
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0013
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0013
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0013, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967887,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0013
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0013 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x79317916 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x793179160x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0018, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x793179160x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x79317916-0x54ffacd8fd0018 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0018, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967888,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0018, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967888,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@736338c8, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0018, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967888,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0018, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967888,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x79317916-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x79317916-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0018
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0018
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0018
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0018, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967889,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0018
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0018 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0018 : Unable to read additional data from server sessionid 0x54ffacd8fd0018, likely server has closed socket
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@17c4fd3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@17c4fd3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@17c4fd3
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.testWiteAndRead(HydraCacheClientImplTest.java:17)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xe3b7c27 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0xe3b7c270x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0019, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xe3b7c270x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xe3b7c27-0x254ffacd97d0019 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0019, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967891,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0019, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967891,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@2e901f36
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4a88d537
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3404cd16, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0019, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967891,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0019, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967891,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0019, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967891,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0019, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967891,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x210b1ffe connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x210b1ffe0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d001a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x210b1ffe0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x210b1ffe-0x254ffacd97d001a connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967915,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967915,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@4c734681, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967915,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967915,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x210b1ffe-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x210b1ffe-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x210b1ffe-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x210b1ffe-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d001a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d001a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d001a
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967916,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d001a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d001a closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d001a : Unable to read additional data from server sessionid 0x254ffacd97d001a, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5ef29fce connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5ef29fce0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d001b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ef29fce0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ef29fce-0x254ffacd97d001b connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967917,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967917,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@9e00bf3, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967917,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967917,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x5ef29fce-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x5ef29fce-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d001b
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d001b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d001b
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967918,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d001b
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d001b : Unable to read additional data from server sessionid 0x254ffacd97d001b, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d001b closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6390c7a connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6390c7a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0014, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6390c7a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6390c7a-0x154ffacdbcb0014 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0014, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967942,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0014, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967942,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7d53ab98, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0014, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967942,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0014, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967942,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6390c7a-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6390c7a-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0014
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0014
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0014
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0014, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967943,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0014
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0014 : Unable to read additional data from server sessionid 0x154ffacdbcb0014, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0014 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x7556ff5d connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x7556ff5d0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d001c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7556ff5d0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x7556ff5d-0x254ffacd97d001c connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967944,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967944,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@21a34a66, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967944,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967944,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x7556ff5d-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x7556ff5d-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d001c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d001c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d001c
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967945,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d001c : Unable to read additional data from server sessionid 0x254ffacd97d001c, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d001c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d001c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@4a88d537
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@4a88d537
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4a88d537
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.setUp(HydraCacheClientImplTest.java:24)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], valueName=Time, about=, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x39ad96d5 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x39ad96d50x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0015, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x39ad96d50x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x39ad96d5-0x154ffacdbcb0015 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0015, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967948,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0015, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967948,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@10ae7918
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@4feaf536
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@21afb917, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0015, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967948,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0015, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967948,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0015, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294967948,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0015, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294967948,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x4f270ec6 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x4f270ec60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d001d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x4f270ec60x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967972,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x4f270ec6-0x254ffacd97d001d connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967972,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@35ce45fe, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967972,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967972,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x4f270ec6-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x4f270ec6-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x4f270ec6-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x4f270ec6-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d001d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d001d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d001d
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967973,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d001d
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d001d closed
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d001d : Unable to read additional data from server sessionid 0x254ffacd97d001d, likely server has closed socket
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x2569539b connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x2569539b0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d001e, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2569539b0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x2569539b-0x254ffacd97d001e connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001e, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967974,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001e, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967974,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@25406d8e, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001e, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967974,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001e, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967974,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x2569539b-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x2569539b-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d001e
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d001e
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d001e
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001e, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294967975,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d001e
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d001e : Unable to read additional data from server sessionid 0x254ffacd97d001e, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d001e closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6da4343e connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6da4343e0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d001f, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6da4343e0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6da4343e-0x254ffacd97d001f connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001f, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294967999,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001f, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294967999,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@ce5af8b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001f, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294967999,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001f, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294967999,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6da4343e-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6da4343e-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x6da4343e-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6da4343e-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d001f
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d001f
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d001f
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d001f, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968000,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d001f : Unable to read additional data from server sessionid 0x254ffacd97d001f, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d001f
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d001f closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1a09f36b connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1a09f36b0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd0019, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1a09f36b0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1a09f36b-0x54ffacd8fd0019 connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0019, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968001,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0019, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968001,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@368c820e, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0019, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968001,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0019, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968001,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1a09f36b-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1a09f36b-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd0019
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd0019
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd0019
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd0019, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968002,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd0019
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd0019 : Unable to read additional data from server sessionid 0x54ffacd8fd0019, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd0019 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1a834885 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1a8348850x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0020, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1a8348850x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1a834885-0x254ffacd97d0020 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0020, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968026,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0020, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968026,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@ac746a1, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0020, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968026,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0020, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968026,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1a834885-metaLookup-shared--pool13-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1a834885-metaLookup-shared--pool13-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x1a834885-shared--pool12-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1a834885-shared--pool12-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0020
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0020
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0020
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0020, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968027,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0020
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0020 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x64399b3a connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x64399b3a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0021, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x64399b3a0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x64399b3a-0x254ffacd97d0021 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0021, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968028,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0021, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968028,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@509693ef, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0021, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968028,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0021, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968028,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x64399b3a-metaLookup-shared--pool15-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x64399b3a-metaLookup-shared--pool15-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0021
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0021
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0021
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0021, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968029,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0021
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0021 : Unable to read additional data from server sessionid 0x254ffacd97d0021, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0021 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6d8cafe1 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6d8cafe10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd001a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6d8cafe10x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6d8cafe1-0x54ffacd8fd001a connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968030,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968030,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5868f6a9, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968030,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968030,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6d8cafe1-metaLookup-shared--pool17-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6d8cafe1-metaLookup-shared--pool17-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd001a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd001a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd001a
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968031,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd001a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd001a closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@4feaf536
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@4feaf536
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@4feaf536
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.setUp(HydraCacheClientImplTest.java:24)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0xe3b7c27 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0xe3b7c270x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0016, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xe3b7c270x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0xe3b7c27-0x154ffacdbcb0016 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0016, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968033,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0016, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968033,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@7a039021
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@60e70884
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@56d06e45, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0016, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968033,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0016, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968033,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0016, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294968033,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0016, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294968033,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x337688d3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x337688d30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0017, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x337688d30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x337688d3-0x154ffacdbcb0017 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0017, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968057,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0017, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968057,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@41109845, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0017, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968057,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0017, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968057,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x337688d3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x337688d3-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x337688d3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x337688d3-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0017
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0017
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0017
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0017, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968058,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0017
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0017 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0017 : Unable to read additional data from server sessionid 0x154ffacdbcb0017, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5ef29fce connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5ef29fce0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0022, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ef29fce0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ef29fce-0x254ffacd97d0022 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0022, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968059,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0022, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968059,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@9e00bf3, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0022, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968059,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0022, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968059,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x5ef29fce-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x5ef29fce-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0022
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0022
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0022
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0022, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968060,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0022
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0022 : Unable to read additional data from server sessionid 0x254ffacd97d0022, likely server has closed socket
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0022 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x4102ab49 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x4102ab490x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0023, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x4102ab490x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x4102ab49-0x254ffacd97d0023 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0023, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968084,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0023, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968084,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@49998942, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0023, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968084,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0023, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968084,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x4102ab49-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x4102ab49-metaLookup-shared--pool8-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x4102ab49-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x4102ab49-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0023
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0023
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0023
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0023, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968085,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0023 : Unable to read additional data from server sessionid 0x254ffacd97d0023, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0023
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0023 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x736338c8 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x736338c80x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd001b, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x736338c80x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x736338c8-0x54ffacd8fd001b connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001b, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968086,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001b, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968086,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@5b54df4, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001b, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968086,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001b, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968086,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x736338c8-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x736338c8-metaLookup-shared--pool10-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd001b
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd001b
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd001b
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001b, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968087,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd001b
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd001b : Unable to read additional data from server sessionid 0x54ffacd8fd001b, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd001b closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x1316f155 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x1316f1550x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0024, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1316f1550x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x1316f155-0x254ffacd97d0024 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0024, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968111,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0024, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968111,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@63f672fe, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0024, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968111,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0024, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968111,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x1316f155-metaLookup-shared--pool13-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1316f155-metaLookup-shared--pool13-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x1316f155-shared--pool12-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x1316f155-shared--pool12-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0024
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0024
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0024
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0024, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968112,0  request:: null response:: null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0024 : Unable to read additional data from server sessionid 0x254ffacd97d0024, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0024
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0024 closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x66b664d7 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x66b664d70x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd001c, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x66b664d70x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x66b664d7-0x54ffacd8fd001c connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968113,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968113,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@161a8d36, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968113,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001c, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968113,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x66b664d7-metaLookup-shared--pool15-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x66b664d7-metaLookup-shared--pool15-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd001c
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd001c
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd001c
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001c, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968114,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd001c
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd001c closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd001c : Unable to read additional data from server sessionid 0x54ffacd8fd001c, likely server has closed socket
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x6c4f37b3 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x6c4f37b30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0018, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6c4f37b30x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x6c4f37b3-0x154ffacdbcb0018 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0018, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968115,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0018, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968115,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7e349634, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0018, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968115,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0018, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968115,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x6c4f37b3-metaLookup-shared--pool17-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x6c4f37b3-metaLookup-shared--pool17-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb0018
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb0018
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb0018
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0018, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968116,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb0018
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb0018 closed
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb0018 : Unable to read additional data from server sessionid 0x154ffacdbcb0018, likely server has closed socket
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@60e70884
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@60e70884
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@60e70884
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 DEBUG main org.apache.hadoop.security.Groups -  Creating new Groups object
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
 DEBUG main org.apache.hadoop.util.NativeCodeLoader - java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 WARN main org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Falling back to shell based
 DEBUG main org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
 DEBUG main org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
 java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:302)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:327)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:78)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:225)
	at org.apache.hadoop.hbase.security.UserProvider.<clinit>(UserProvider.java:56)
	at org.apache.hadoop.hbase.client.HConnectionKey.<init>(HConnectionKey.java:71)
	at org.apache.hadoop.hbase.client.ConnectionManager.getConnectionInternal(ConnectionManager.java:298)
	at org.apache.hadoop.hbase.client.HBaseAdmin.<init>(HBaseAdmin.java:235)
	at com.hydra.hydracache.client.HydraCacheHbaseAdmin.<init>(HydraCacheHbaseAdmin.java:15)
	at com.hydra.hydracache.client.HydraCacheClientImpl.createTable(HydraCacheClientImpl.java:102)
	at com.hydra.hydracache.client.HydraCacheClientImplTest.setUp(HydraCacheClientImplTest.java:24)
	at junit.framework.TestCase.runBare(TestCase.java:125)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.junit3.JUnit3TestReference.run(JUnit3TestReference.java:130)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)
DEBUG main org.apache.hadoop.util.Shell - setsid exited with exit code 0
 DEBUG main org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
 DEBUG main org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
 DEBUG main org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login
 DEBUG main org.apache.hadoop.security.UserGroupInformation - hadoop login commit
 DEBUG main org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: hadoop
 DEBUG main org.apache.hadoop.security.UserGroupInformation - UGI loginUser:hadoop (auth:SIMPLE)
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x18d6cf4 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.7.0_101
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/hadoop/workspace/hydracache/target/test-classes:/home/hadoop/workspace/hydracache/target/classes:/home/hadoop/.m2/repository/junit/junit/3.8.1/junit-3.8.1.jar:/home/hadoop/.m2/repository/redis/clients/jedis/2.8.0/jedis-2.8.0.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-pool2/2.3/commons-pool2-2.3.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-client/1.2.1/hbase-client-1.2.1.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-annotations/1.2.1/hbase-annotations-1.2.1.jar:/home/hadoop/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-common/1.2.1/hbase-common-1.2.1.jar:/home/hadoop/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/hadoop/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/hadoop/.m2/repository/org/apache/hbase/hbase-protocol/1.2.1/hbase-protocol-1.2.1.jar:/home/hadoop/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/hadoop/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/hadoop/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/hadoop/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/hadoop/.m2/repository/com/google/guava/guava/12.0.1/guava-12.0.1.jar:/home/hadoop/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/hadoop/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/hadoop/.m2/repository/io/netty/netty-all/4.0.23.Final/netty-all-4.0.23.Final.jar:/home/hadoop/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-api/1.6.1/slf4j-api-1.6.1.jar:/home/hadoop/.m2/repository/org/slf4j/slf4j-log4j12/1.6.1/slf4j-log4j12-1.6.1.jar:/home/hadoop/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/hadoop/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/hadoop/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/hadoop/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/hadoop/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-common/2.5.1/hadoop-common-2.5.1.jar:/home/hadoop/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/hadoop/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/hadoop/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/hadoop/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/home/hadoop/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/hadoop/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/hadoop/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/hadoop/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/hadoop/.m2/repository/org/apache/avro/avro/1.7.4/avro-1.7.4.jar:/home/hadoop/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/hadoop/.m2/repository/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar:/home/hadoop/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/home/hadoop/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/hadoop/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.1/hadoop-mapreduce-client-core-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.1/hadoop-yarn-common-2.5.1.jar:/home/hadoop/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/hadoop/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/hadoop/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/hadoop/.m2/repository/io/netty/netty/3.6.2.Final/netty-3.6.2.Final.jar:/home/hadoop/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-client/2.5.1/hadoop-client-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.1/hadoop-hdfs-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.1/hadoop-mapreduce-client-app-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.1/hadoop-mapreduce-client-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.1/hadoop-yarn-client-2.5.1.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/hadoop/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.1/hadoop-yarn-server-common-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.1/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/hadoop/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.1/hadoop-yarn-api-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.1/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/hadoop/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.1/hadoop-annotations-2.5.1.jar:/home/hadoop/.eclipse/org.eclipse.platform_3.8_155965261/configuration/org.eclipse.osgi/bundles/129/1/.cp/
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=:/usr/lib/oracle/11.2/client64//lib:/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:os.version=3.13.0-85-generic
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.name=hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/hadoop
 INFO main org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/hadoop/workspace/hydracache
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x18d6cf40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 DEBUG main org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb0019, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x18d6cf40x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x18d6cf4-0x154ffacdbcb0019 connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0019, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968118,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0019, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968118,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
 DEBUG main org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
 DEBUG main org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
 DEBUG main org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@3ac81c24
 DEBUG main org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG main org.apache.hadoop.hdfs.shortcircuit.DomainSocketFactory - Both short-circuit local reads and UNIX domain socket are disabled.
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@48ae27b0, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0019, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968118,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0019, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968118,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG htable-pool1-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0019, packet:: clientPath:null serverPath:null finished:false header:: 5,3  replyHeader:: 5,4294968118,0  request:: '/hbase,F  response:: s{4294967301,4294967301,1464578408984,1464578408984,0,16,0,0,0,16,4294967383} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb0019, packet:: clientPath:null serverPath:null finished:false header:: 6,4  replyHeader:: 6,4294968118,0  request:: '/hbase/master,F  response:: #ffffffff000146d61737465723a313630303074ffffff9cfffffff4ffffff85ffffffd7ffffffffffffff99ffffffec50425546a1ea126d61737465722e6b6466353030302e636f6d10ffffff807d18ffffffd4ffffffe4ffffffb3fffffffdffffffcf2a10018ffffff8a7d,s{4294967314,4294967314,1464578412039,1464578412039,0,0,0,168040203967856640,66,0,4294967314} 
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service MasterService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to master.kdf5000.com/172.17.0.2:16000
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Started disable of test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Disabled test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Deleted test
 INFO main org.apache.hadoop.hbase.client.HBaseAdmin - Created test
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x3837f691 connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x3837f6910x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave1.kdf5000.com/172.17.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave1.kdf5000.com/172.17.0.3:2181, initiating session
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave1.kdf5000.com/172.17.0.3:2181
 INFO main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave1.kdf5000.com/172.17.0.3:2181, sessionid = 0x154ffacdbcb001a, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3837f6910x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x3837f691-0x154ffacdbcb001a connected
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb001a, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968142,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb001a, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968142,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@591f7e6f, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb001a, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968142,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb001a, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968142,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x3837f691-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x3837f691-metaLookup-shared--pool3-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG hconnection-0x3837f691-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x3837f691-shared--pool2-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x154ffacdbcb001a
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x154ffacdbcb001a
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x154ffacdbcb001a
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x154ffacdbcb001a, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968143,0  request:: null response:: null
 DEBUG main-SendThread(slave1.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x154ffacdbcb001a : Unable to read additional data from server sessionid 0x154ffacdbcb001a, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x154ffacdbcb001a
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x154ffacdbcb001a closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x5ca99bc connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x5ca99bc0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server master.kdf5000.com/172.17.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to master.kdf5000.com/172.17.0.2:2181, initiating session
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on master.kdf5000.com/172.17.0.2:2181
 INFO main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server master.kdf5000.com/172.17.0.2:2181, sessionid = 0x54ffacd8fd001d, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ca99bc0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x5ca99bc-0x54ffacd8fd001d connected
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001d, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968144,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001d, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968144,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6ff37c33, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001d, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968144,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001d, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968144,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x5ca99bc-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x5ca99bc-metaLookup-shared--pool5-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x54ffacd8fd001d
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x54ffacd8fd001d
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x54ffacd8fd001d
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x54ffacd8fd001d, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968145,0  request:: null response:: null
 DEBUG main-SendThread(master.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x54ffacd8fd001d : Unable to read additional data from server sessionid 0x54ffacd8fd001d, likely server has closed socket
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x54ffacd8fd001d
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x54ffacd8fd001d closed
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 INFO main org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper - Process identifier=hconnection-0x242109db connecting to ZooKeeper ensemble=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181
 INFO main org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181 sessionTimeout=90000 watcher=hconnection-0x242109db0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Opening socket connection to server slave2.kdf5000.com/172.17.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Socket connection established to slave2.kdf5000.com/172.17.0.4:2181, initiating session
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment request sent on slave2.kdf5000.com/172.17.0.4:2181
 INFO main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Session establishment complete on server slave2.kdf5000.com/172.17.0.4:2181, sessionid = 0x254ffacd97d0025, negotiated timeout = 90000
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x242109db0x0, quorum=master.kdf5000.com:2181,slave1.kdf5000.com:2181,slave2.kdf5000.com:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
 DEBUG main-EventThread org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher - hconnection-0x242109db-0x254ffacd97d0025 connected
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0025, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,4294968146,0  request:: '/hbase/hbaseid,F  response:: s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0025, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,4294968146,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3136303030ffffff88ffffffb63cffffffdcffffff8a67203a50425546a2434386565383863322d383263392d343532392d396466382d646637636233343663373233,s{4294967317,4294967317,1464578415864,1464578415864,0,0,0,0,67,0,4294967317} 
 DEBUG main org.apache.hadoop.hbase.ipc.AbstractRpcClient - Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@ae0a000, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0025, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,4294968146,0  request:: '/hbase,F  response:: v{'meta-region-server,'backup-masters,'table,'draining,'region-in-transition,'table-lock,'running,'master,'namespace,'hbaseid,'online-snapshot,'replication,'splitWAL,'recovering-regions,'rs,'flush-table-proc} 
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0025, packet:: clientPath:null serverPath:null finished:false header:: 4,4  replyHeader:: 4,4294968146,0  request:: '/hbase/meta-region-server,F  response:: #ffffffff0001a726567696f6e7365727665723a3136303230ffffff99fffffffbffffffc1ffffffbd595e69fffffff150425546a1ea12736c617665312e6b6466353030302e636f6d10ffffff947d18ffffffdcffffffe1ffffffb3fffffffdffffffcf2a100183,s{4294967370,4294967370,1464578423266,1464578423266,0,0,0,0,71,0,4294967370} 
 DEBUG hconnection-0x242109db-metaLookup-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG hconnection-0x242109db-metaLookup-shared--pool7-t1 org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave1.kdf5000.com/172.17.0.3:16020
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Use SIMPLE authentication for service ClientService, sasl=false
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Connecting to slave2.kdf5000.com/172.17.0.4:16020
 INFO main org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation - Closing zookeeper sessionid=0x254ffacd97d0025
 DEBUG main org.apache.zookeeper.ZooKeeper - Closing session: 0x254ffacd97d0025
 DEBUG main org.apache.zookeeper.ClientCnxn - Closing client for session: 0x254ffacd97d0025
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x254ffacd97d0025, packet:: clientPath:null serverPath:null finished:false header:: 5,-11  replyHeader:: 5,4294968147,0  request:: null response:: null
 DEBUG main org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x254ffacd97d0025
 DEBUG main-SendThread(slave2.kdf5000.com:2181) org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x254ffacd97d0025 : Unable to read additional data from server sessionid 0x254ffacd97d0025, likely server has closed socket
 INFO main-EventThread org.apache.zookeeper.ClientCnxn - EventThread shut down
 INFO main org.apache.zookeeper.ZooKeeper - Session: 0x254ffacd97d0025 closed
 DEBUG main org.apache.hadoop.hbase.ipc.RpcClientImpl - Stopping rpc client
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@5f4c9b52
 DEBUG Thread-2 org.apache.hadoop.ipc.Client - Stopping client
 